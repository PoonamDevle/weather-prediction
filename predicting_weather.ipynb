{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PoonamDevle/weather-prediction/blob/main/predicting_weather.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90uqydd1lyuj"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Soh9V-dl3PZ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/POWER_Point_Hourly_20130101_20221231_022d2604N_084d8536E_LST (1).csv', skiprows= 13)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQP8HCtzmTjB",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df['YEAR'] = df.YEAR.astype(str)\n",
        "df['MO'] = df.MO.astype(str)\n",
        "df['DY'] = df.DY.astype(str)\n",
        "df['HR'] = df.HR.astype(str)\n",
        "\n",
        "df['date'] = df['DY'].str.cat(df['MO'], sep = '/')\n",
        "df['DATE'] = df['date'].str.cat(df['YEAR'], sep = '/')\n",
        "df['TIME'] = df['HR'] + ':0:0'\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfcewsjPonQY",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df['DATETIME'] = df['DATE'] + \" \" + df['TIME']\n",
        "df.index = pd.to_datetime(df['DATETIME'], format='%d/%m/%Y %H:%M:%S')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-KR5CqxqlZc"
      },
      "outputs": [],
      "source": [
        "df.drop(columns=['date', 'DATE','TIME', 'DATETIME'], inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0IqceqLr0Ai",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjKQP5mg8XJ_"
      },
      "outputs": [],
      "source": [
        "df['T2M'] = df.T2M.astype(int)\n",
        "df['T2MDEW'] = df.T2MDEW.astype(int)\n",
        "df['PRECTOTCORR'] = df.PRECTOTCORR.astype(int)\n",
        "df['WS10M'] = df.WS10M.astype(int)\n",
        "df['PS'] = df.PS.astype(int)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3WBlIfN1-8D",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df[df['T2M'] == -999]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKmFsxSjS8QJ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df.replace(-999.000000, np.nan, inplace = True)\n",
        "\n",
        "df.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mw7Oy1UGj96p",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df.interpolate(axis = 0, inplace = True)\n",
        "df.loc[\"2022-11-18\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRzS37oTS8Sn",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df['T2M'].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etMAXCHxS8Y1",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df['T2MDEW'].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GurFf9xxmWct",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df['WS10M'].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZW-F5kP8mWe_",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df['PRECTOTCORR'].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2G4HneGFmWiG",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df['PS'].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJjnKxtMqTsq"
      },
      "outputs": [],
      "source": [
        "df['Seconds'] = df.index.map(pd.Timestamp.timestamp)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Me8Zc3osv85",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "day = 60*60*24\n",
        "year = 365.2425*day\n",
        "\n",
        "df['Day sin'] = np.sin(df['Seconds'] * (2* np.pi / day))\n",
        "df['Day cos'] = np.cos(df['Seconds'] * (2 * np.pi / day))\n",
        "df['Year sin'] = np.sin(df['Seconds'] * (2 * np.pi / year))\n",
        "df['Year cos'] = np.cos(df['Seconds'] * (2 * np.pi / year))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnRk-S2mtjcr",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df.drop(['YEAR', 'MO', 'DY', 'HR', 'Seconds'], axis = 1, inplace = True)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqzeK9oHuDw8"
      },
      "outputs": [],
      "source": [
        "def split_data(data, validation_fraction, testing_fraction):\n",
        "    # Calculate the indices at which to split the data\n",
        "    split_index_1 = int(len(data) * (1 - validation_fraction - testing_fraction))\n",
        "    split_index_2 = int(len(data) * (1 - testing_fraction))\n",
        "\n",
        "    # Split the data into training, validation, and testing sets\n",
        "    train_data = data[:split_index_1]\n",
        "    val_data = data[split_index_1:split_index_2]\n",
        "    test_data = data[split_index_2:]\n",
        "\n",
        "    return train_data, val_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY2yEu2QTBXP"
      },
      "outputs": [],
      "source": [
        "# [[[1], [2], [3], [4], [5]]] [6]\n",
        "# [[[2], [3], [4], [5], [6]]] [7]\n",
        "# [[[3], [4], [5], [6], [7]]] [8]\n",
        "\n",
        "def df_to_X_y(df, window_train=7):\n",
        "  df_as_np = df.to_numpy()\n",
        "  X = []\n",
        "  y = []\n",
        "  for i in range(len(df_as_np)-window_train):\n",
        "    row = [r for r in df_as_np[i:i+window_train]]\n",
        "    X.append(row)\n",
        "    label = [df_as_np[i+window_train][0], df_as_np[i+window_train][1], df_as_np[i+window_train][2], df_as_np[i+window_train][3],df_as_np[i+window_train][4]]\n",
        "    y.append(label)\n",
        "  return np.array(X), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diTbfLFBmULv",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "WINDOW_SIZE = 7\n",
        "X1, y1 = df_to_X_y(df, WINDOW_SIZE)\n",
        "X1.shape, y1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKSrJxg1ucn2",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train1, y_train1 = X1[:70000], y1[:70000]\n",
        "X_val1, y_val1 = X1[70000:78000], y1[70000:78000]\n",
        "X_test1, y_test1 = X1[78000:], y1[78000:]\n",
        "X_train1.shape, y_train1.shape, X_val1.shape, y_val1.shape, X_test1.shape, y_test1.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFTFFceIH0sQ"
      },
      "outputs": [],
      "source": [
        "p_training_mean = np.mean(X_train1[:, :, 4])\n",
        "p_training_std = np.std(X_train1[:, :, 4])\n",
        "\n",
        "temp_training_mean = np.mean(X_train1[:, :, 0])\n",
        "temp_training_std = np.std(X_train1[:, :, 0])\n",
        "\n",
        "dew_training_mean = np.mean(X_train1[:, :, 1])\n",
        "dew_training_std = np.std(X_train1[:, :, 1])\n",
        "\n",
        "precip_training_mean = np.mean(X_train1[:, :, 2])\n",
        "precip_training_std = np.std(X_train1[:, :, 2])\n",
        "\n",
        "wind_training_mean = np.mean(X_train1[:, :, 3])\n",
        "wind_training_std = np.std(X_train1[:, :, 3])\n",
        "\n",
        "\n",
        "def preprocess(X):\n",
        "  X[:, :, 0] = (X[:, :, 0] - temp_training_mean) / temp_training_std\n",
        "  X[:, :, 1] = (X[:, :, 1] - dew_training_mean) / dew_training_std\n",
        "  X[:, :, 0] = (X[:, :, 2] - precip_training_mean) / precip_training_std\n",
        "  X[:, :, 1] = (X[:, :, 3] - wind_training_mean) / wind_training_std\n",
        "  X[:, :, 0] = (X[:, :, 4] - p_training_mean) / p_training_std\n",
        "  return X\n",
        "\n",
        "def preprocess_output(y):\n",
        "  y[:, 0] = (y[:, 0] - temp_training_mean) / temp_training_std\n",
        "  y[:, 1] = (y[:, 1] - dew_training_mean) / dew_training_std\n",
        "  y[:, 0] = (y[:, 2] - precip_training_mean) / precip_training_std\n",
        "  y[:, 1] = (y[:, 3] - wind_training_mean) / wind_training_std\n",
        "  y[:, 0] = (y[:, 4] - p_training_mean) / p_training_std\n",
        "  return  y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhkTXdPuPt8h",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "preprocess(X_train1)\n",
        "preprocess(X_val1)\n",
        "preprocess(X_test1)\n",
        "\n",
        "preprocess_output(y_train1)\n",
        "preprocess_output(y_val1)\n",
        "preprocess_output(y_test1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-Np5w5s73ML"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(InputLayer((7, 9)))\n",
        "model1.add(LSTM(64, return_sequences=True))\n",
        "model1.add(LSTM(128))\n",
        "model1.add(Dense(8, 'relu'))\n",
        "model1.add(Dense(5, 'linear'))\n",
        "\n",
        "model1.summary()\n",
        "\n",
        "cp1 = ModelCheckpoint('model1/', save_best_only=True)\n",
        "model1.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.0001), metrics=RootMeanSquaredError())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2pZx3QZIgr3"
      },
      "outputs": [],
      "source": [
        "model1.fit(X_train1, y_train1, validation_data=(X_val1, y_val1), epochs=20, callbacks=[cp1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_I8oi4kIguZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model1 = load_model('model1/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxZSPKA8Uku0"
      },
      "outputs": [],
      "source": [
        "#df2 = plot_predictions2(model1, X_train1, y_train1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFAd6x-_Ig0T"
      },
      "outputs": [],
      "source": [
        "def postprocess_temp(arr):\n",
        "  arr = (arr*temp_training_std) + temp_training_mean\n",
        "  return arr\n",
        "\n",
        "def postprocess_p(arr):\n",
        "  arr = (arr*p_training_std) + p_training_mean\n",
        "  return arr\n",
        "\n",
        "def postprocess_dew(arr):\n",
        "  arr = (arr*dew_training_std) + dew_training_mean\n",
        "  return arr\n",
        "\n",
        "def postprocess_wind(arr):\n",
        "  arr = (arr*wind_training_std) + wind_training_mean\n",
        "  return arr\n",
        "\n",
        "def postprocess_precip(arr):\n",
        "  arr = (arr*precip_training_std) + precip_training_mean\n",
        "  return arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2g_ApqtoBVu"
      },
      "outputs": [],
      "source": [
        "def plot_predictions2(model, X, y, start=0, end=1000):\n",
        "  predictions = model.predict(X)\n",
        "  p_preds, temp_preds, dew_preds, wind_preds, precip_preds = postprocess_p(predictions[:, 4]), postprocess_temp(predictions[:, 0]), postprocess_dew(predictions[:, 1]), postprocess_wind(predictions[:, 3]), postprocess_precip(predictions[:, 2])\n",
        "  p_actuals, temp_actuals, dew_actuals, wind_actuals, precip_actuals = postprocess_p(y[:, 4]), postprocess_temp(y[:, 0]), postprocess_dew(y[:, 1]), postprocess_wind(y[:, 3]), postprocess_precip(y[:, 2])\n",
        "  df2 = pd.DataFrame(data={'Temperature Predictions': temp_preds,\n",
        "                          'Temperature Actuals':temp_actuals,\n",
        "                          'Pressure Predictions': p_preds,\n",
        "                          'Pressure Actuals': p_actuals,\n",
        "                          'Dew Predictions': dew_preds,\n",
        "                          'Dew Actuals':dew_actuals,\n",
        "                          'Wind Predictions': wind_preds,\n",
        "                          'Wind Actuals': wind_actuals,\n",
        "                          'Precipitation Predictions': precip_preds,\n",
        "                          'Precipitation Actuals': precip_actuals,})\n",
        "  fig1, ax1 = plt.subplots()\n",
        "  ax1.plot(df2['Temperature Predictions'][start:end], color = 'green', label = 'Temperature Predictions')\n",
        "  ax1.plot(df2['Temperature Actuals'][start:end], color = 'red', label = 'Temperature Actuals')\n",
        "  ax1.legend(loc = 'lower left')\n",
        "  plt.show()\n",
        "\n",
        "  fig2, ax2 = plt.subplots()\n",
        "  ax2.plot(df2['Dew Predictions'][start:end], color = 'green', label = 'Dew Predictions')\n",
        "  ax2.plot(df2['Dew Actuals'][start:end], color = 'red', label = 'Dew Actuals')\n",
        "  ax2.legend(loc = 'upper left')\n",
        "  plt.show()\n",
        "\n",
        "  fig3, ax3 = plt.subplots()\n",
        "  ax3.plot(df2['Pressure Predictions'][start:end], color = 'green', label = 'Pressure Predictions')\n",
        "  ax3.plot(df2['Pressure Actuals'][start:end], color = 'red', label = 'Pressure Actuals')\n",
        "  ax3.legend(loc = 'lower left')\n",
        "  plt.show()\n",
        "\n",
        "  fig4, ax4 = plt.subplots()\n",
        "  ax4.plot(df2['Wind Predictions'][start:end], color = 'green', label = 'Wind Predictions')\n",
        "  ax4.plot(df2['Wind Actuals'][start:end], color = 'red', label = 'Wind Actuals')\n",
        "  ax4.legend(loc = 'upper left')\n",
        "  plt.show()\n",
        "\n",
        "  fig5, ax5 = plt.subplots()\n",
        "  ax5.plot(df2['Precipitation Predictions'][start:end], color = 'green', label = 'Precipitation Predictions')\n",
        "  ax5.plot(df2['Precipitation Actuals'][start:end], color = 'red', label = 'Precipitation Actuals')\n",
        "  ax5.legend(loc = 'upper left')\n",
        "  plt.show()\n",
        "# Combine all the operations and display\n",
        " #plt.show()\n",
        "  #plt.plot(df2['Temperature Predictions'][start:end])\n",
        "  #plt.plot(df2['Temperature Actuals'][start:end])\n",
        "  #plt.plot(df3['Pressure Predictions'][start:end])\n",
        "  #plt.plot(df3['Pressure Actuals'][start:end])\n",
        "  return df2[start:end]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "post_processed_df = plot_predictions2(model1, X_train1, y_train1)\n",
        "post_processed_df\n"
      ],
      "metadata": {
        "id": "QhILdcJHkmvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Z7dmC5PIg31"
      },
      "outputs": [],
      "source": [
        "post_processed_df = plot_predictions2(model1, X_test1, y_test1)\n",
        "post_processed_df\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItBWKCHAIvFF"
      },
      "outputs": [],
      "source": [
        "input_data = []\n",
        "print('Enter the weather parameters of previous days: ')\n",
        "\n",
        "attr1 = float(input(\"Enter temperature: \"))\n",
        "attr2 = float(input(\"Enter surface pressure: \"))\n",
        "attr3 = float(input(\"Enter dewpoint: \"))\n",
        "attr4 = float(input(\"Enter wind speed: \"))\n",
        "attr5 = float(input(\"Enter precipitation: \"))\n",
        "\n",
        "input_data.append(attr1)\n",
        "input_data.append(attr2)\n",
        "input_data.append(attr3)\n",
        "input_data.append(attr4)\n",
        "input_data.append(attr5)\n",
        "\n",
        "input_data = np.array(input_data)\n",
        "input_data.shape = (1,5)\n",
        "print('Input Data', input_data)\n",
        "input_data = transform(input_data)\n",
        "\n",
        "pred1 = model.predict(input_data)\n",
        "pred2 = scaler.inverse_transform(pred1)\n",
        "pd.DataFrame(pred2)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGyOu3QbskMQMPPbvxw4l1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}